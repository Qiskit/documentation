---
title: Run jobs in a batch
description: How to run quantum computing jobs in batch mode using Qiskit Runtime.

---

# Run jobs in a batch

Use batch mode to submit multiple primitive jobs simultaneously. Following are examples of working with batches.

## Set up to use batches

Before starting a batch, you must [set up Qiskit Runtime](/guides/install-qiskit) and initialize it as a service:

```python
from qiskit_ibm_runtime import QiskitRuntimeService, Batch, SamplerV2 as Sampler, EstimatorV2 as Estimator

service = QiskitRuntimeService()
```


## Open a batch

You can open a runtime batch by using the context manager `with Batch(...)` or by initializing the `Batch`
class. When you start a batch,  you must specify a QPU by passing a `backend` object.  The batch starts when its first job begins execution.


**Batch class**

```python
from qiskit_ibm_runtime import Batch, SamplerV2 as Sampler, EstimatorV2 as Estimator

backend = service.least_busy(operational=True, simulator=False)
batch = Batch(backend=backend)
estimator = Estimator(mode=batch)
sampler = Sampler(mode=batch)
# Close the batch because no context manager was used.
batch.close()
```

**Context manager**

The context manager automatically opens and closes the batch.

```python
from qiskit_ibm_runtime import Batch, SamplerV2 as Sampler, EstimatorV2 as Estimator

backend = service.least_busy(operational=True, simulator=False)
with Batch(backend=backend):
  estimator = Estimator()
  sampler = Sampler()
```

<span id="specify-batch-length"></span>
## Batch length

You can define the batch's maximum time to live (TTL) with the `max_time` parameter. This should exceed the longest job's execution time. This timer starts when the batch starts.  When the value is reached, the batch is closed.  Any jobs that are running will finish, but jobs still queued are failed.

```python
with Batch(backend=backend, max_time="25m"):
  ...
```

There is also an interactive time to live (interactive TTL) value that cannot be configured.  If no batch jobs are queued within that window, the batch is temporarily deactivated.

Default values:

| Instance type (Open or Premium Plan) | Interactive TTL | Maximum TTL |
| --- | --- | --- |
| Both Open and Premium Plan | 1 sec | 10 min |

To determine a batch's max TTL or interactive TTL, follow the instructions in [Determine batch details](#batch-details) and look for the `max_time`or `interactive_timeout` value, respectively.

<span id="close"></span>
## Close a batch

A batch automatically closes when it exits the context manager. When the batch context manager is exited, the batch is put into "In progress, not accepting new jobs" status. This means that the batch finishes processing all running or queued jobs until the maximum TTL value is reached. After all jobs are completed, the batch is immediately closed. You cannot submit jobs to a closed batch.

```python
with Batch(backend=backend) as batch:
    estimator = Estimator()
    job1 = estimator.run(...)
    job2 = estimator.run(...)

# The batch is no longer accepting jobs but the submitted job will run to completion.
result = job1.result()
result2 = job2.result()
```

<Admonition type="tip">
If you are not using a context manager, manually close the batch.  If you leave the batch open and submit more jobs to it later, it is possible that the maximum TTL will be reached before the subsequent jobs start running; causing them to be canceled. You can close a batch as soon as you are done submitting jobs to it. When a batch is closed with `batch.close()`, it no longer accepts new jobs, but the already submitted jobs will still run until completion and their results can be retrieved.
</Admonition>

```python
batch = Batch(backend=backend)

# If using qiskit-ibm-runtime earlier than 0.24.0, change `mode=` to `batch=`
estimator = Estimator(mode=batch)
job1 = estimator.run(...)
job2 = estimator.run(...)
print(f"Result1: {job1.result()}")
print(f"Result2: {job2.result()}")

# Manually close the batch. Running and queued jobs will run to completion.
batch.close()
```

<span id="batch-details"></span>
## Determine batch details

For a comprehensive overview of a batch's configuration and status, including its interactive and max TTL, use the  `batch.details() method`.

```python
from qiskit_ibm_runtime import QiskitRuntimeService, batch, SamplerV2 as Sampler

service = QiskitRuntimeService()
backend = service.least_busy(operational=True, simulator=False)

with Batch(backend=backend) as batch:
    print(batch.details())
```

<span id="partition"></span>
## Reconfigure jobs for parallel processing

There are multiple ways you can reconfigure your jobs to take advantage of the parallel processing provided by batching. The following example shows how you can partition a long list of circuits into multiple jobs and run them as a batch to take advantage of the parallel processing.

```python
from qiskit_ibm_runtime import SamplerV2 as Sampler, Batch

max_circuits = 100
all_partitioned_circuits = []
for i in range(0, len(circuits), max_circuits):
    all_partitioned_circuits.append(circuits[i : i + max_circuits])
jobs = []
start_idx = 0

with Batch(backend=backend):
    sampler = Sampler()
    for partitioned_circuits in all_partitioned_circuits:
        job = sampler.run(partitioned_circuits)
        jobs.append(job)
```

<Admonition type="caution">
    If you set `backend=backend` in a primitive, the program is run in job mode, even if it's inside a batch or session context. Setting `backend=backend` is deprecated as of Qiskit Runtime 0.24.0.  Instead, use the `mode` parameter.
</Admonition>

## Next steps

<Admonition type="tip" title="Recommendations">
  - Try an example in the [Combine error mitigation options with the estimator primitive](https://learning.quantum.ibm.com/tutorial/combine-error-mitigation-options-with-the-estimator-primitive) tutorial.
  - Review the [Batch API](/api/qiskit-ibm-runtime/batch#batch) reference.
  - Understand the [Job limits](/guides/job-limits) when sending a job to an IBM QPU.
</Admonition>