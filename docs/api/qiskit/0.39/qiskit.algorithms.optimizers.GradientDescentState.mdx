---
title: GradientDescentState
description: API reference for qiskit.algorithms.optimizers.GradientDescentState
in_page_toc_min_heading_level: 1
python_api_type: class
python_api_name: qiskit.algorithms.optimizers.GradientDescentState
---

# GradientDescentState

<Class id="qiskit.algorithms.optimizers.GradientDescentState" isDedicatedPage={true} github="https://github.com/qiskit/qiskit/tree/stable/0.22/qiskit/algorithms/optimizers/gradient_descent.py" signature="GradientDescentState(x, fun, jac, nfev, njev, nit, stepsize, learning_rate)" modifiers="class">
  Bases: [`qiskit.algorithms.optimizers.steppable_optimizer.OptimizerState`](qiskit.algorithms.optimizers.OptimizerState "qiskit.algorithms.optimizers.steppable_optimizer.OptimizerState")

  State of [`GradientDescent`](qiskit.algorithms.optimizers.GradientDescent "qiskit.algorithms.optimizers.GradientDescent").

  Dataclass with all the information of an optimizer plus the learning\_rate and the stepsize.

  ## Attributes

  ### stepsize

  <Attribute id="qiskit.algorithms.optimizers.GradientDescentState.stepsize" attributeTypeHint="Optional[float]">
    Norm of the gradient on the last step.
  </Attribute>

  ### learning\_rate

  <Attribute id="qiskit.algorithms.optimizers.GradientDescentState.learning_rate" attributeTypeHint="qiskit.algorithms.optimizers.optimizer_utils.learning_rate.LearningRate">
    Learning rate at the current step of the optimization process.

    It behaves like a generator, (use `next(learning_rate)` to get the learning rate for the next step) but it can also return the current learning rate with `learning_rate.current`.
  </Attribute>

  ### x

  <Attribute id="qiskit.algorithms.optimizers.GradientDescentState.x" attributeTypeHint="Union[float, numpy.ndarray]">
    Current optimization parameters.
  </Attribute>

  ### fun

  <Attribute id="qiskit.algorithms.optimizers.GradientDescentState.fun" attributeTypeHint="Optional[Callable[[Union[float, numpy.ndarray]], float]]">
    Function being optimized.
  </Attribute>

  ### jac

  <Attribute id="qiskit.algorithms.optimizers.GradientDescentState.jac" attributeTypeHint="Optional[Callable[[Union[float, numpy.ndarray]], Union[float, numpy.ndarray]]]">
    Jacobian of the function being optimized.
  </Attribute>

  ### nfev

  <Attribute id="qiskit.algorithms.optimizers.GradientDescentState.nfev" attributeTypeHint="Optional[int]">
    Number of function evaluations so far in the optimization.
  </Attribute>

  ### njev

  <Attribute id="qiskit.algorithms.optimizers.GradientDescentState.njev" attributeTypeHint="Optional[int]">
    Number of jacobian evaluations so far in the opimization.
  </Attribute>

  ### nit

  <Attribute id="qiskit.algorithms.optimizers.GradientDescentState.nit" attributeTypeHint="Optional[int]">
    Number of optmization steps performed so far in the optimization.
  </Attribute>
</Class>

